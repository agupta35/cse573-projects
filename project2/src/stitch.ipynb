{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-06T15:50:25.845421Z",
     "start_time": "2019-04-06T15:50:25.544364Z"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from plot_utils import convert_and_plot \n",
    "from matcher import get_good_matches, kNN_matcher\n",
    "from img_utils import get_direction, get_homography, ransac\n",
    "\n",
    "from functools import cmp_to_key\n",
    "from collections import Counter\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-07T18:22:40.743382Z",
     "start_time": "2019-04-07T18:22:40.730683Z"
    }
   },
   "outputs": [],
   "source": [
    "class Image:\n",
    "    \"\"\"\n",
    "    Each Image object consists of the image, keypoints &\n",
    "    descriptors.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, img, kp=None, des=None):\n",
    "        self.img = img\n",
    "        self.shape = img.shape\n",
    "        sift = cv2.xfeatures2d.SIFT_create()\n",
    "\n",
    "        if kp is None or des is None:\n",
    "            self.kp, self.des = sift.detectAndCompute(self.img, None)\n",
    "        else:\n",
    "            self.kp = kp\n",
    "            self.des = des\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        return (self.img == other.img).all()\n",
    "\n",
    "    def __hash__(self):\n",
    "        return hash((tuple(row) for row in self.img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-07T20:12:39.519025Z",
     "start_time": "2019-04-07T20:12:39.202162Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ateendraramesh/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:19: DeprecationWarning: elementwise == comparison failed; this will raise an error in the future.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'bool' object has no attribute 'all'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-226-f0d0361e7f31>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0mconvert_and_plot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpanorama\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m \u001b[0mstitch_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../data/mountain/\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-226-f0d0361e7f31>\u001b[0m in \u001b[0;36mstitch_images\u001b[0;34m(path_to_directory, verbose)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;31m# Alignment step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     I = sorted(list(set(images)),\n\u001b[0m\u001b[1;32m     29\u001b[0m                key=cmp_to_key(lambda x, y:\n\u001b[1;32m     30\u001b[0m                               get_direction(x.kp, y.kp,\n",
      "\u001b[0;32m<ipython-input-166-4f2accc97ecd>\u001b[0m in \u001b[0;36m__eq__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__eq__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__hash__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'bool' object has no attribute 'all'"
     ]
    }
   ],
   "source": [
    "def stitch_images(path_to_directory, verbose=False):\n",
    "    \"\"\"\n",
    "    Input - Path from images should be read from \n",
    "    Returns - None\n",
    "\n",
    "    This function reads the images from the given\n",
    "    path, aligns it and writes result into panorama.jpg\n",
    "    \"\"\"\n",
    "    # Get image paths in given directory\n",
    "    image_paths = glob.glob(path_to_directory + \"/*\")\n",
    "\n",
    "    # Read all these images with cv2.imread\n",
    "    images = [cv2.imread(image_path) \n",
    "              for image_path in image_paths \n",
    "              if \"panorama\" not in image_path]\n",
    "\n",
    "    # Image dimensions\n",
    "    h, w, _ = images[0].shape\n",
    "\n",
    "    # Convert each of these images to Image class\n",
    "    for i, image in enumerate(images):\n",
    "        images[i] = Image(image)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Read\", i + 1, \"images\")\n",
    "\n",
    "    # Alignment step\n",
    "    I = sorted(list(set(images)),\n",
    "               key=cmp_to_key(lambda x, y:\n",
    "                              get_direction(x.kp, y.kp,\n",
    "                                            x.des, y.des,\n",
    "                                            x.img, y.img)))\n",
    "\n",
    "    # Plot all images if necessary\n",
    "    if verbose:\n",
    "        print(\"Found\", i + 1 - len(I), \"duplicate images\")\n",
    "        for i in range(len(I)):\n",
    "            convert_and_plot(I[i].img)\n",
    "\n",
    "    def warp_two_images(I1, I2, H):\n",
    "        '''\n",
    "        warp img2 to img1 with homograph H\n",
    "        Referred from - https://stackoverflow.com/questions/13063201/how-to-show-the-whole-image-when-using-opencv-warpperspective\n",
    "        '''\n",
    "        H /= H[-1, -1]\n",
    "        h1, w1 = I1.shape[:2]\n",
    "        h2, w2 = I2.shape[:2]\n",
    "        pts1 = np.float32([[0, 0], [0, h1], [w1, h1], [w1, 0]]).reshape(-1, 1, 2)\n",
    "        pts2 = np.float32([[0, 0], [0, h2], [w2, h2], [w2, 0]]).reshape(-1, 1, 2)\n",
    "        pts2_ = cv2.perspectiveTransform(pts2, H)\n",
    "        pts = np.concatenate((pts1, pts2_), axis=0)\n",
    "        [xmin, ymin] = np.int32(pts.min(axis=0).ravel() - 0.5)\n",
    "        [xmax, ymax] = np.int32(pts.max(axis=0).ravel() + 0.5)\n",
    "        t = [-xmin, -ymin]\n",
    "        Ht = np.array(\n",
    "            [\n",
    "                [1, 0, t[0]], \n",
    "                [0, 1, t[1]], \n",
    "                [0, 0, 1]\n",
    "            ]\n",
    "        )  # translate\n",
    "\n",
    "        result = cv2.warpPerspective(I2.img, \n",
    "                                     Ht.dot(H),\n",
    "                                     (xmax - xmin, ymax - ymin))\n",
    "        result[t[1]: h1 + t[1], t[0]: w1 + t[0]] = I1.img\n",
    "\n",
    "        return result\n",
    "    \n",
    "    def stitch_2_images(I1, I2):\n",
    "        if not isinstance(I1, Image):\n",
    "            I1 = Image(I1)\n",
    "        if not isinstance(I2, Image):\n",
    "            I2 = Image(I2)\n",
    "        matches = get_good_matches(kNN_matcher(I1.des, I2.des))\n",
    "        H, _ = ransac(matches, I1.kp, I2.kp)\n",
    "        panorama = warp_two_images(I1, I2, np.linalg.inv(H))\n",
    "        return panorama\n",
    "    \n",
    "    assert(2 <= len(I) <= 3)\n",
    "    if len(I) == 2:\n",
    "        panorama = stitch_2_images(I[0], I[1])\n",
    "        \n",
    "    else:\n",
    "        panorama = stitch_2_images(I[1], I[2])\n",
    "        panorama = stitch_2_images(I[0], panorama)\n",
    "        \n",
    "    convert_and_plot(panorama)\n",
    "\n",
    "stitch_images(\"../data/mountain/\", verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
